{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reduction\n",
    "\n",
    "The Artportalen Dataset is *large*. The purpose of this notebook is to remove information we do not need. To execute it, your working directory should contain a folder called ’data’, itself containing a CSV file called ’artportalen.csv’.\n",
    "\n",
    "As a reminder, the artportalen dataset can be downloaded [here](https://www.gbif.org/dataset/38b4c89f-584c-41bb-bd8f-cd1def33e92f). It will be downloaded in the form of a ~15GB zip which will unzip into a ~60GB CSV. The name of the downloaded file will be generated when you will download it, so you should rename it to ’artportalen.csv’ one unzipped.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is *slow* (but a one time cost) and shouldn't be run multiple times if it works for you. Moreover, it will generate ~13GB of files. Once done, you can remove the original artportalen dataset from your disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 gbifID\n",
      "1 datasetKey\n",
      "2 occurrenceID\n",
      "3 kingdom\n",
      "4 phylum\n",
      "5 class\n",
      "6 order\n",
      "7 family\n",
      "8 genus\n",
      "9 species\n",
      "10 infraspecificEpithet\n",
      "11 taxonRank\n",
      "12 scientificName\n",
      "13 verbatimScientificName\n",
      "14 verbatimScientificNameAuthorship\n",
      "15 countryCode\n",
      "16 locality\n",
      "17 stateProvince\n",
      "18 occurrenceStatus\n",
      "19 individualCount\n",
      "20 publishingOrgKey\n",
      "21 decimalLatitude\n",
      "22 decimalLongitude\n",
      "23 coordinateUncertaintyInMeters\n",
      "24 coordinatePrecision\n",
      "25 elevation\n",
      "26 elevationAccuracy\n",
      "27 depth\n",
      "28 depthAccuracy\n",
      "29 eventDate\n",
      "30 day\n",
      "31 month\n",
      "32 year\n",
      "33 taxonKey\n",
      "34 speciesKey\n",
      "35 basisOfRecord\n",
      "36 institutionCode\n",
      "37 collectionCode\n",
      "38 catalogNumber\n",
      "39 recordNumber\n",
      "40 identifiedBy\n",
      "41 dateIdentified\n",
      "42 license\n",
      "43 rightsHolder\n",
      "44 recordedBy\n",
      "45 typeStatus\n",
      "46 establishmentMeans\n",
      "47 lastInterpreted\n",
      "48 mediaType\n",
      "49 issue\n"
     ]
    }
   ],
   "source": [
    "f = open('data/artportalen.csv', 'r')\n",
    "header = f.readline().replace(\"\\n\", '').split(\"\\t\")\n",
    "f.close()\n",
    "\n",
    "for i, column in enumerate(header):\n",
    "    print(i, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we are not interested in every column. Even some useful column could/should be removed (as long as we can reconstruct the information) to produce a more manageable file size/\n",
    " - Included in the data folder is a ’species.csv’ file, which allows for the reconstruction of columns 3 to 13 only from column 33. I suggest we trim those columns except for 12 (for human readability, for now) and only keep column 33. \n",
    " - Location and date data should be kept, they are at the center of the project\n",
    " - Locality and region may get useful to ponder the number of observation by population (although I am not sure it is a good idea). UPDATE : after examining the ’locality’ column, it is disgusting to the point of being unusable. \n",
    "\n",
    "In the end, once the CSV read, we keep the entries at the following indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scientificName', 'taxonKey', 'taxonRank', 'stateProvince', 'decimalLatitude', 'decimalLongitude', 'coordinateUncertaintyInMeters', 'day', 'month', 'year']\n"
     ]
    }
   ],
   "source": [
    "kept_indices = [12, 33, 11, 17, 21, 22, 23, 30, 31, 32]\n",
    "print([header[i] for i in kept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14e27bf94c24ec0bbd5b818bc1a974a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108073382 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 7940273 lines out of 108073382, i.e. 7.35%\n",
      "Skipped 7895663 lines because of missing values, and 44610 lines because of formatting issues.\n",
      "Kept 100133109 lines.\n"
     ]
    }
   ],
   "source": [
    "count_format = 0 # to count the number of imcomplete rows we discard\n",
    "count_na = 0 # to count the number of rows with missing values\n",
    "nb_lines = 108_073_381 # number of rows - SHOULD BE UPDATED FOR NEWER VERSIONS OF THE DATASET\n",
    "\n",
    "f = open(\"data/artportalen.csv\", \"r\")\n",
    "out = open(\"data/artportalen_trimmed.csv\", \"w\")\n",
    "\n",
    "# Annoyingly, the fields contain some usual separators, such as ',', '\\t' and even ';'.\n",
    "# We use \"|\" anyway, because its presence in a field indicates an issue anyway.\n",
    "# We will store the lines that contain a \";\" in a the following in a separate file, and treat them separately.\n",
    "# CAVEAT: if the \";\" is in a field after the 33rd, we will not catch it, as it does not cause alignment issues.\n",
    "out_badly_formatted = open(\"data/artportalen_badly_formatted.csv\", \"w\")\n",
    "\n",
    "f.readline() # skip the first line\n",
    "out.write(\";\".join([header[i] for i in kept_indices]) + \"\\n\")\n",
    "\n",
    "for line in tqdm(f, total=nb_lines):\n",
    "\n",
    "    line = line.replace(\"\\n\", '').split(\"\\t\")\n",
    "    if any(\";\" in field for field in line[:33]):\n",
    "        out_badly_formatted.write(\"|\".join(line) + \"\\n\")\n",
    "        count_format += 1\n",
    "        continue\n",
    "    line = [str(line[k]) for k in kept_indices]\n",
    "\n",
    "    # if all fields are not filled, we discard the line\n",
    "    if not all(line):\n",
    "        count_na += 1\n",
    "        continue\n",
    "\n",
    "    to_write = \";\".join(line) + \"\\n\"\n",
    "    out.write(to_write)\n",
    "\n",
    "f.close()\n",
    "out.close()\n",
    "out_badly_formatted.close()\n",
    "\n",
    "count = count_na + count_format\n",
    "print(f\"Skipped {count} lines out of {nb_lines}, i.e. {count/nb_lines*100:.2f}%\")\n",
    "print(f\"Skipped {count_na} lines because of missing values, and {count_format} lines because of formatting issues.\")\n",
    "print(f\"Kept {nb_lines - count} lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we select only the rows that contain observations of arthropods, from the trimmed data we have generated. Since we have removed the explicit mention of that information, we will have to recover it from the ’species.csv’ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7b61b111ba41a092bdbd38199dd1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100133108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 6406801 lines in the new file.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/artportalen_trimmed.csv\", \"r\")\n",
    "out = open(\"data/artportalen_arthropods.csv\", \"w\")\n",
    "\n",
    "count = 0 # to count the number of arthropods\n",
    "\n",
    "f.readline() # skip header\n",
    "out.write(\";\".join([header[i] for i in kept_indices]) + \"\\n\")\n",
    "\n",
    "for line in tqdm(f, total = 100133108):\n",
    "    taxonKey = int(line.split(\";\")[1])\n",
    "    if taxonKey in arthropods_keys:\n",
    "        out.write(line)\n",
    "        count += 1\n",
    "f.close()\n",
    "out.close()\n",
    "\n",
    "print(f\"Wrote {count} lines in the new file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arthro_df = pd.read_csv(\"data/artportalen_arthropods.csv\", sep=\";\")\n",
    "arthro_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ’artportalen_arthropods.csv’ is small enough to be held in memory (~800MB) but still unwieldy. In the following, we replace the text entries by more compact datatypes. First, we build dictionnaries for ’taxonRank, locality, stateProvince’. We do so directly from the artportalen_trimmed dataset to future proof the construction. We also lose the ’scientificName’ in favor of the taxonKey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d2c83ae39840bc88fcf5f3ff3f8681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100133108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"data/artportalen_trimmed.csv\", \"r\")\n",
    "rank_dict = {}\n",
    "prov_dict = {}\n",
    "\n",
    "f.readline() # skip header\n",
    "\n",
    "for line in tqdm(f, total = 100133108):\n",
    "    rank, prov = line.split(\";\")[2:4]\n",
    "    if rank not in rank_dict:\n",
    "        rank_dict[rank] = len(rank_dict) + 1\n",
    "    if prov not in prov_dict:\n",
    "        prov_dict[prov] = len(prov_dict) + 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b6a1988a7f42a898647b0c04196c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6406801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"data/artportalen_arthropods.csv\", \"r\")\n",
    "out = open(\"data/arthropods_compressed.csv\", \"w\")\n",
    "\n",
    "f.readline() # skip header\n",
    "out.write(\";\".join([header[i] for i in kept_indices][1:]) + \"\\n\")\n",
    "\n",
    "for line in tqdm(f, total = 6406801):\n",
    "    line = line.split(\";\")\n",
    "    line[2] = str(rank_dict[line[2]])\n",
    "    line[3] = str(prov_dict[line[3]])\n",
    "    out.write(\";\".join(line[1:]))\n",
    "\n",
    "f.close()\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remember the inverse mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_rank = open(\"data/ranks.csv\", \"w\")\n",
    "for k, v in rank_dict.items():\n",
    "    key_to_rank.write(f\"{v};{k}\\n\")\n",
    "key_to_rank.close()\n",
    "\n",
    "key_to_prov = open(\"data/provinces.csv\", \"w\")\n",
    "for k, v in prov_dict.items():\n",
    "    key_to_prov.write(f\"{v};{k}\\n\")\n",
    "key_to_prov.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6406801 entries, 0 to 6406800\n",
      "Data columns (total 9 columns):\n",
      " #   Column                         Dtype  \n",
      "---  ------                         -----  \n",
      " 0   taxonKey                       int64  \n",
      " 1   taxonRank                      int64  \n",
      " 2   stateProvince                  int64  \n",
      " 3   decimalLatitude                float64\n",
      " 4   decimalLongitude               float64\n",
      " 5   coordinateUncertaintyInMeters  float64\n",
      " 6   day                            int64  \n",
      " 7   month                          int64  \n",
      " 8   year                           int64  \n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 439.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "arthro_df = pd.read_csv(\"data/arthropods_compressed.csv\", sep=\";\")\n",
    "arthro_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxonKey</th>\n",
       "      <th>taxonRank</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>coordinateUncertaintyInMeters</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "      <td>6.406801e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.514375e+06</td>\n",
       "      <td>1.080315e+00</td>\n",
       "      <td>1.043600e+01</td>\n",
       "      <td>5.851040e+01</td>\n",
       "      <td>1.554494e+01</td>\n",
       "      <td>2.480183e+02</td>\n",
       "      <td>1.570498e+01</td>\n",
       "      <td>6.616672e+00</td>\n",
       "      <td>2.012136e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.310070e+06</td>\n",
       "      <td>5.773583e-01</td>\n",
       "      <td>5.910404e+00</td>\n",
       "      <td>2.391516e+00</td>\n",
       "      <td>2.272081e+00</td>\n",
       "      <td>2.662950e+03</td>\n",
       "      <td>8.857103e+00</td>\n",
       "      <td>1.610713e+00</td>\n",
       "      <td>1.497431e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.533700e+01</td>\n",
       "      <td>1.006286e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.749000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.773163e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.667865e+01</td>\n",
       "      <td>1.356081e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.009000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.986171e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>5.810863e+01</td>\n",
       "      <td>1.562799e+01</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.017000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.086570e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>5.958938e+01</td>\n",
       "      <td>1.716239e+01</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.021000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.238534e+07</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>6.905934e+01</td>\n",
       "      <td>2.416028e+01</td>\n",
       "      <td>6.400798e+06</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.024000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           taxonKey     taxonRank  stateProvince  decimalLatitude  \\\n",
       "count  6.406801e+06  6.406801e+06   6.406801e+06     6.406801e+06   \n",
       "mean   3.514375e+06  1.080315e+00   1.043600e+01     5.851040e+01   \n",
       "std    2.310070e+06  5.773583e-01   5.910404e+00     2.391516e+00   \n",
       "min    5.400000e+01  1.000000e+00   1.000000e+00     5.533700e+01   \n",
       "25%    1.773163e+06  1.000000e+00   6.000000e+00     5.667865e+01   \n",
       "50%    1.986171e+06  1.000000e+00   1.000000e+01     5.810863e+01   \n",
       "75%    5.086570e+06  1.000000e+00   1.500000e+01     5.958938e+01   \n",
       "max    1.238534e+07  9.000000e+00   3.400000e+01     6.905934e+01   \n",
       "\n",
       "       decimalLongitude  coordinateUncertaintyInMeters           day  \\\n",
       "count      6.406801e+06                   6.406801e+06  6.406801e+06   \n",
       "mean       1.554494e+01                   2.480183e+02  1.570498e+01   \n",
       "std        2.272081e+00                   2.662950e+03  8.857103e+00   \n",
       "min        1.006286e+01                   1.000000e+00  1.000000e+00   \n",
       "25%        1.356081e+01                   5.000000e+01  8.000000e+00   \n",
       "50%        1.562799e+01                   1.000000e+02  1.600000e+01   \n",
       "75%        1.716239e+01                   2.500000e+02  2.300000e+01   \n",
       "max        2.416028e+01                   6.400798e+06  3.100000e+01   \n",
       "\n",
       "              month          year  \n",
       "count  6.406801e+06  6.406801e+06  \n",
       "mean   6.616672e+00  2.012136e+03  \n",
       "std    1.610713e+00  1.497431e+01  \n",
       "min    1.000000e+00  1.749000e+03  \n",
       "25%    6.000000e+00  2.009000e+03  \n",
       "50%    7.000000e+00  2.017000e+03  \n",
       "75%    8.000000e+00  2.021000e+03  \n",
       "max    1.200000e+01  2.024000e+03  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthro_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly ’coordinateUncertaintyInMeters’ contains some nonsensical values. How many values are above 5km ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A negligible proportion (0.00%) of rows have an uncertainty greater than 5km. Let's remove them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    6405697\n",
       "mean         245\n",
       "std          550\n",
       "min            1\n",
       "25%           50\n",
       "50%          100\n",
       "75%          250\n",
       "max         5000\n",
       "Name: coordinateUncertaintyInMeters, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = len(arthro_df[arthro_df[\"coordinateUncertaintyInMeters\"] > 5000])/len(arthro_df)*100\n",
    "print(f\"A negligible proportion ({prop:.2f}%) of rows have an uncertainty greater than 5km. Let's remove them.\")\n",
    "arthro_df.drop(arthro_df[arthro_df[\"coordinateUncertaintyInMeters\"] > 5000].index, inplace=True)\n",
    "arthro_df[\"coordinateUncertaintyInMeters\"].describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91     500.0\n",
       "0.92     500.0\n",
       "0.93     750.0\n",
       "0.94    1000.0\n",
       "0.95    1000.0\n",
       "0.96    1000.0\n",
       "0.97    1000.0\n",
       "0.98    1500.0\n",
       "0.99    2500.0\n",
       "1.00    5000.0\n",
       "Name: coordinateUncertaintyInMeters, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arthro_df[\"coordinateUncertaintyInMeters\"].quantile([0.9 + 0.01*k for k in range(1, 11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of the data, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
